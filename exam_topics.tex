\documentclass[twocolumn, a4paper, 11pt]{scrartcl}

\usepackage{amsmath, amssymb}
\usepackage[left=1.50cm, right=0.50cm, top=0.50cm, bottom=3cm]{geometry}
    \title{Exam CompStat: 26.7.17 16:00}
\begin{document}

    \maketitle

    \begin{itemize}
      \item $y_i$, $\hat{y}$ RV
      \item $< y > = \mu_y$ not random $\rightarrow$ Prior
    \end{itemize}

    \section{Basic Properties of random Variables}

      \begin{itemize}
        \item Transitional, cond.prob., joint prob. margin
        \[
          \int p(x,y) dy = f(x)
        \]
        \item law of error propagation
        \begin{align*}
          \sigma^2_y = \sigma^2_x*(dy/dx)^2\\
          P(x|y) = P(x,y)/P(y)
        \end{align*}
      \end{itemize}

    \section{Distributions}\label{distributions}

    \begin{itemize}
      \item uniform, binomial, poissonian, (multivariate-) gaussian, $\chi^2$, exponential
        \begin{align*}
          f(x) > 0\\
          \int f(x) d x = 1
        \end{align*}
      \item PDF
        \[ f(x)dx\]
      \item CDF
        \[ int(f(x), x, -Inf, y) = g(y)\]
      \item MGF
        \[
          < e^{tx} > = \int e^{tx} f(x) dx
        \]
      \item moments
        \begin{align*}
          \int x^m f(x) dx\\
          \int (x-\alpha)^m f(x) dx
        \end{align*}
    \end{itemize}

    \section{Bayes Theorem}\label{bayes-theorem}

    \begin{itemize}
    \item hi
      \begin{align*}
        P(d, t)\\
        G(x, \mu) = e^{-\frac 1 2 \frac{(x-\mu)^2}{\sigma^2}}\\
        P(D|T) = P(D,T)/P(T)\\
        P(T|D) = P(D,T)/P(D)
      \end{align*}
    \item frequentists approach
      \begin{align*}
        P(D,T) = \ldots\\
        d_i, \hat d = \sum_i \frac{d_i}{N} = f\text{ of data}\\
        < \hat d > = \mu\\
        \rightarrow\ \text{PDF}(\hat \theta)\text{ (PDF of estimator)}
      \end{align*}

    \item Bayes Theorem
      \begin{align*}
        P(T|D) = P(D|T) \frac{P(T)}{P(D)}\\
        E(D) = \int L(D|T) \pi(T) dT\\
        B_{a,b} = \frac{E_a(D)}{E_b(D)}
      \end{align*}

    \end{itemize}

    \section{Fisher Estimation}

    \begin{align*}
      F_{\alpha, \beta} = \left. \frac{\partial^2 log(L)}{\partial  \theta_\alpha \partial \theta_\beta} \right|_{L_{max}}
    \end{align*}

    \begin{itemize}
    \item
      we assume gaussian distributed parameters around the peak for a found maximum
      likelihood estimator
      \[
        e^{-\frac 12 (x_i-\mu_i)  C_{i,j}^{-1} (x_j-\mu_j)}
      \]
    \end{itemize}

    \section{fitting}\label{fitting}

    \begin{align*}
      t = f(x) = A_0 + A_1  f_1(x) + A_2  f_2(x)\\
      e^{-\frac12 \sum_i \frac{(d_i-t_i)^2}{\sigma_i^2} }
      \Rightarrow C_{i,j}\\
      A |_{L_{max}} = G^{-1} D, F_{\alpha, \beta} = G
    \end{align*}

\end{document}
